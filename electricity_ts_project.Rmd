---
title: "Electricity Time Series Project"
output: html_document
date: "2023-05-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

path <- "/Users/alisonwong/git/electricity-time-series"
knitr::opts_knit$set(root.dir = path)
setwd(path)

# Load Packages 
library(tidyverse)
library(latex2exp)
library(forecast)
library(tidyverse)
library(tseries)
```

# Read in data and perform data cleaning and wrangling 
```{r}
# Read data 
energy <- read.csv("energy-ca.csv")

# Subset data to select columns we need: Year, Month, State, Megawatts (sold)
energy_df <- subset(energy, select = c("X", "X.1", "X.2", "X.16"))
energy_df <- energy_df[-c(1,2),] # remove first two rows (unnecessary as these rows were the result of a small issue when importing the file)

# Add column names
colnames(energy_df) <- c("Year", "Month", "State", "Megawatts")
table(grepl("CA", energy_df$State)) # check the amount of times in which "CA" appears in the "X.2" column which corresponds to the respective state

# Subset data to select California 
energy_df <- energy_df[energy_df$State == "CA",]

# Get rid of empty rows
row.names(energy_df) <- NULL

# Check the amount of times in which the State column equals "CA". Since this number, 158, matches with the earlier number, we have support to say no important data was lost
table(grepl("CA", energy_df$State))
```

# Arrange data to create a time series object
```{r}
# Change to integers
energy_df$Year <- as.integer(energy_df$Year)
energy_df$Month <- as.integer(energy_df$Month)
energy_df$Megawatts <- as.integer(gsub(",", "", energy_df$Megawatts))

# Arrange energy_df in ascending order of time
energy_df <- energy_df %>%
  arrange(Year, Month)
head(energy_df)

# Remove the 2023 year as only Jan and Feb data is present
energy_df <- energy_df[energy_df$Year != 2023,]
```

# Perform time series analysis

First, we compute the yearly average $\hat m_j$ over all months a $\hat m_j=\frac{1}{12}\sum_{k=1}^{12}x_{j,k}$ and eliminate the yearly trend.

We detrended the time series using a two-sided moving average because (don't know)
```{r}
# Get overall trend by moving average window of 12
m_t <- ma(energy_ts, order = 12, centre = T)
ts.plot(energy_ts,
        xlab = "Year",
        ylab = "Electricity Sold in Megawatts",
        main = "Electricity (Megawatts) Sold in California with Yearly Average")
lines(m_t, col = "red")
```
From the time series model, we can see that there is a seasonal trend in our electricity data with a peak in electricity sold in months around the summer of 2019.  

```{r}
# Overall trend
ts.plot(m_t,
        xlab = "Year",
        ylab = "Electricity Sold in Megawatts",
        main = "Overall Trend")

# Detrend only
detrend <- energy_ts - m_t
```
The yearly average remains fairly constant from 2010 to 2022 with a slight drop from 2018 to 2020.

Next, we will isolate the seasonality to get our residuals.
```{r}
# Plot new time series that clearly exposes seasonality
ts.plot(detrend,
        xlab = "Year",
        ylab = "Electricity Sold in Megawatts",
        main = "Electricity Sold (Megawatts) after Detrending")

# Get seasonality from detrended time series
s_t <- t(matrix(data = detrend, nrow = 12))

# Monthly seasonality: use matrix of 12 rows
s_t <- colMeans(s_t, na.rm = T)
ts.plot(rep(s_t,12), xlab = "Year", ylab = "Electricity Sold in Megawatts", main = "Seasonality")
```

# Analyze residuals
```{r}
# Decomposed time series by detrending and deseasonalizing
# Extract residuals
z_t <- energy_ts - m_t - s_t

# Plot time series, ACF, histogram, QQ-plot of white noise
checkresiduals(z_t)
qqnorm(z_t)
qqline(z_t, col = "red")
```

Check for stationarity using the Augmented Dickey-Fuller test
```{r}
# Augmented Dickey–Fuller test
adf.test(z_t[7:150]) # since we used the two-sided MA, the first 6 and last 6 points are NA
mean(z_t, na.rm= TRUE)
```
Since the p-value is smaller than 0.05, we reject the null hypothesis and conclude that our residuals are stationary. The mean of our residuals rounds to 0, we can conclude that our residuals follows white noise.

# Analyze the “rough” component

Compute ACF of the time series
```{r}
#acf(energy_ts, lag = length(energy_ts) - 1) # not sure why the x axis is wrong
#acf <- acf(energy_ts,plot=FALSE)$acf

checkresiduals(energy_ts)
```
The ACF of the time series tails off, meaning that it is likely not a MA(q) process. We will compute and plot PACF to check if the model fits an AR(p) model process.

Compute PACF of the time series
```{r}
pacf(energy_ts, lag = length(energy_ts) - 1, 
     main = "PACF of Time Series") # not sure why the x axis is wrong

#pacf <- pacf(energy_ts, plot=FALSE)

model <- ar(energy_ts, order.max=30)
model
```
ar() function returned an AR(12) model, which is reasonable to us. 

# Fit ARMA Model

We we create a new time series dataframe from 2010 to 2021 with our fitted AR model to predict 2022, This will allow us to see if our model can predict the time series accurately. To quantify that, we will calculate the prediction error of our model's predicted values with the actual values of the data. 
```{r}
# For a given time series x we can fit the autoregressive (AR) model using the arima() command and setting order equal to c(1, 0, 0). Note for reference that an AR model is an ARIMA(1, 0, 0) model.
energytest_ts <- ts(energytest[,4], start= 2010, frequency = 12)

#Fitting the AR Model to the time series
AR <- arima(energytest_ts, order = c(11,0,0)) # why can't do 12
print(AR)

#plotting the series along with the fitted values
ts.plot(energytest_ts)
AR_fit <- energytest_ts - residuals(AR)
points(AR_fit, type = "l", col = 2, lty = 2)
```

# Predict future values
```{r}
#Using predict() to make a 1 year (12 months) forecast
predict_AR <- predict(AR, n.ahead = 12)
predict_AR

forecast <- predict_AR$pred
forecast_se <- predict_AR$se

# Plot the time series (with 2022) with the 2022 forecast and 95% prediction intervals
plot(energy_ts)
points(forecast, type = "l", col = 2, lwd = 2)
points(forecast - 2*forecast_se, type = "l", col = "blue", lty = 2, lwd = 0.2)
points(forecast + 2*forecast_se, type = "l", col = "blue", lty = 2, lwd = 0.2)
legend("topleft", lty=1, bty = "n", col=c("red","black"), c("predicted values","actual values"))
```
Predicted 2022

```{r}
# Calculate prediction error
accuracy(predict_AR$pred, energy_ts[145:156])
``` 
the best model had the lowest error (particularly the MAPE, Mean absolute percentage error)


```{r}
#Using predict() to make a 1 year (12 months) forecast
predict5 <- predict(AR, n.ahead = 12*5)

forecast5 <- predict5$pred
forecast_se5 <- predict5$se

# Plot the time series (with 2022) with the 2022 forecast and 95% prediction intervals
plot(energy_ts, xlim = c(2010, 2027), 
     main = "Time series predictions from 2022 to 2026")
points(forecast5, type = "l", col = 2, lwd = 2)
points(forecast5 - 2*forecast_se5, type = "l", col = "blue", lty = 2, lwd = 0.2)
points(forecast5 + 2*forecast_se5, type = "l", col = "blue", lty = 2, lwd = 0.2)
legend("topleft", lty=1, bty = "n", col=c("red","black"), c("predicted values","actual values"))
```
5 years

# Spectral Analysis
```{r}
spectrum()
```

References:

ADF test https://www.r-bloggers.com/2022/06/augmented-dickey-fuller-test-in-r/
Source for decomposition https://anomaly.io/seasonal-trend-decomposition-in-r/index.html


https://rpubs.com/RatherBit/90267
https://rpubs.com/JSHAH/481706
